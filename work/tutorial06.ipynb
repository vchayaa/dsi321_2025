{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d2b421-b3cc-4440-b0c7-654039057708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/site-packages (19.0.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (2025.3.2)\n",
      "Requirement already satisfied: s3fs in /usr/local/lib/python3.11/site-packages (2025.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /usr/local/lib/python3.11/site-packages (from s3fs) (2.21.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/site-packages (from s3fs) (3.11.18)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.37.2,>=1.37.0 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.4.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/site-packages (from botocore<1.37.2,>=1.37.0->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.2.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas pyarrow fsspec s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d7818c-7931-4e06-a76c-6b90abd7a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# API endpoint and parameters\n",
    "WEATHER_ENDPOINT = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "API_KEY = \"a8830679af88ae345ed7fb6aac741e34\"  # Replace with your actual API key\n",
    "\n",
    "\n",
    "provinces = {\n",
    "    \"Pathum Thani\":{\n",
    "        \"lat\": 14.0134,\n",
    "        \"lon\": 100.5304\n",
    "    },\n",
    "    \"Bangkok\":{\n",
    "            \"lat\": 13.7367,\n",
    "            \"lon\": 100.5232\n",
    "    },\n",
    "    \"Chiang Mai\":{\n",
    "        \"lat\": 18.7883,\n",
    "        \"lon\": 98.9853\n",
    "    },\n",
    "    \"Phuket\":{\n",
    "        \"lat\": 7.9519,\n",
    "        \"lon\": 98.3381\n",
    "    }\n",
    "}\n",
    "# Function to fetch and process weather data\n",
    "def get_weather_data(province='Pathum Thani'):\n",
    "    \n",
    "    params = {\n",
    "        \"lat\": provinces[province]['lat'],\n",
    "        \"lon\": provinces[province]['lon'],\n",
    "        \"appid\": API_KEY,\n",
    "        \"units\": \"metric\"\n",
    "    }\n",
    "    try:\n",
    "        # Make API request\n",
    "        response = requests.get(WEATHER_ENDPOINT, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        data = response.json()\n",
    "        \n",
    "        # Convert timestamp to datetime\n",
    "        # created_at = datetime.fromtimestamp(data['dt'])\n",
    "\n",
    "        dt = datetime.now()\n",
    "        thai_tz = pytz.timezone('Asia/Bangkok')\n",
    "        created_at = dt.replace(tzinfo=thai_tz)\n",
    "\n",
    "\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        # Create dictionary with required fields\n",
    "        weather_dict = {\n",
    "            'timestamp': timestamp,\n",
    "            'year': timestamp.year,\n",
    "            'month': timestamp.month,\n",
    "            'day': timestamp.day,\n",
    "            'hour': timestamp.hour,\n",
    "            'minute': timestamp.minute,\n",
    "            'created_at': created_at,\n",
    "            'requested_province':province,\n",
    "            'location': data['name'],\n",
    "            'weather_main': data['weather'][0]['main'],\n",
    "            'weather_description': data['weather'][0]['description'],\n",
    "            'main.temp': data['main']['temp']\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        # df = pd.DataFrame([weather_dict])\n",
    "        \n",
    "        # return df\n",
    "        return weather_dict\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"Error processing data: Missing key {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19fa0be2-9d17-46a7-9065-4507629fd910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype                       \n",
      "---  ------               --------------  -----                       \n",
      " 0   timestamp            4 non-null      datetime64[ns]              \n",
      " 1   year                 4 non-null      int64                       \n",
      " 2   month                4 non-null      int64                       \n",
      " 3   day                  4 non-null      int64                       \n",
      " 4   hour                 4 non-null      int64                       \n",
      " 5   minute               4 non-null      int64                       \n",
      " 6   created_at           4 non-null      datetime64[ns, Asia/Bangkok]\n",
      " 7   requested_province   4 non-null      object                      \n",
      " 8   location             4 non-null      object                      \n",
      " 9   weather_main         4 non-null      object                      \n",
      " 10  weather_description  4 non-null      object                      \n",
      " 11  main.temp            4 non-null      float64                     \n",
      "dtypes: datetime64[ns, Asia/Bangkok](1), datetime64[ns](1), float64(1), int64(5), object(4)\n",
      "memory usage: 516.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>created_at</th>\n",
       "      <th>requested_province</th>\n",
       "      <th>location</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>main.temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-02 07:31:34.207809</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-02 07:49:34.201424+07:00</td>\n",
       "      <td>Pathum Thani</td>\n",
       "      <td>Pathum Thani</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>32.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-02 07:31:34.683904</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-02 07:49:34.683889+07:00</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>34.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-02 07:31:34.782698</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-02 07:49:34.782686+07:00</td>\n",
       "      <td>Chiang Mai</td>\n",
       "      <td>Chiang Mai</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>34.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-02 07:31:34.892172</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-05-02 07:49:34.892161+07:00</td>\n",
       "      <td>Phuket</td>\n",
       "      <td>Kathu</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>30.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  year  month  day  hour  minute  \\\n",
       "0 2025-05-02 07:31:34.207809  2025      5    2     7      31   \n",
       "1 2025-05-02 07:31:34.683904  2025      5    2     7      31   \n",
       "2 2025-05-02 07:31:34.782698  2025      5    2     7      31   \n",
       "3 2025-05-02 07:31:34.892172  2025      5    2     7      31   \n",
       "\n",
       "                        created_at requested_province      location  \\\n",
       "0 2025-05-02 07:49:34.201424+07:00       Pathum Thani  Pathum Thani   \n",
       "1 2025-05-02 07:49:34.683889+07:00            Bangkok       Bangkok   \n",
       "2 2025-05-02 07:49:34.782686+07:00         Chiang Mai    Chiang Mai   \n",
       "3 2025-05-02 07:49:34.892161+07:00             Phuket         Kathu   \n",
       "\n",
       "  weather_main weather_description  main.temp  \n",
       "0       Clouds          few clouds      32.36  \n",
       "1         Rain          light rain      34.44  \n",
       "2       Clouds    scattered clouds      34.22  \n",
       "3       Clouds          few clouds      30.92  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([get_weather_data(p) for p in list(provinces.keys())])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bdd175b-f75b-43d7-92ef-2a83237e3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 07:31:35.485335+06:42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt = datetime.now()\n",
    "thai_tz = pytz.timezone('Asia/Bangkok')\n",
    "dt = dt.replace(tzinfo=thai_tz)\n",
    "print(dt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f77c2b-a1be-46c4-9537-cd7aca2c0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# lakeFS credentials from your docker-compose.yml\n",
    "ACCESS_KEY = \"access_key\"\n",
    "SECRET_KEY = \"secret_key\"\n",
    "\n",
    "# lakeFS endpoint (running locally)\n",
    "lakefs_endpoint = \"http://lakefs-dev:8000/\"\n",
    "\n",
    "# lakeFS repository, branch, and file path\n",
    "repo = \"weather\"\n",
    "branch = \"main\"\n",
    "path = \"weather.parquet\"\n",
    "\n",
    "# Construct the full lakeFS S3-compatible path\n",
    "lakefs_s3_path = f\"s3a://{repo}/{branch}/{path}\"\n",
    "\n",
    "# Configure storage_options for lakeFS (S3-compatible)\n",
    "storage_options = {\n",
    "    \"key\": ACCESS_KEY,\n",
    "    \"secret\": SECRET_KEY,\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": lakefs_endpoint\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9052d7-5834-4242-8fb5-2df9ed4b4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    lakefs_s3_path,\n",
    "    storage_options=storage_options,\n",
    "    partition_cols=['year','month','day','hour'],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4545df5e-b3f6-4c46-a196-7334bb0af669",
   "metadata": {},
   "source": [
    "# test read parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9703e66e-ea17-47cf-9067-4cca2fa8c2b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "weather3/main/weather.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m path_all_partition = \u001b[33m'\u001b[39m\u001b[33ms3a://weather3/main/weather.parquet\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df2=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m    \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_all_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df2.info()\n\u001b[32m      8\u001b[39m df2.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    664\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    665\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/io/parquet.py:274\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[32m    268\u001b[39m     path,\n\u001b[32m    269\u001b[39m     filesystem,\n\u001b[32m    270\u001b[39m     storage_options=storage_options,\n\u001b[32m    271\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    272\u001b[39m )\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     pa_table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     result = pa_table.to_pandas(**to_pandas_kwargs)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/parquet/core.py:1793\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[39m\n\u001b[32m   1787\u001b[39m     warnings.warn(\n\u001b[32m   1788\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_legacy_dataset\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated as of pyarrow 15.0.0 \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1789\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand will be removed in a future version.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1790\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1792\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m     dataset = \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1807\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1810\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[32m   1813\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/parquet/core.py:1371\u001b[39m, in \u001b[36mParquetDataset.__init__\u001b[39m\u001b[34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[39m\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m partitioning == \u001b[33m\"\u001b[39m\u001b[33mhive\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1368\u001b[39m     partitioning = ds.HivePartitioning.discover(\n\u001b[32m   1369\u001b[39m         infer_dictionary=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28mself\u001b[39m._dataset = \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mparquet_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/dataset.py:794\u001b[39m, in \u001b[36mdataset\u001b[39m\u001b[34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[39m\n\u001b[32m    783\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    784\u001b[39m     schema=schema,\n\u001b[32m    785\u001b[39m     filesystem=filesystem,\n\u001b[32m   (...)\u001b[39m\u001b[32m    790\u001b[39m     selector_ignore_prefixes=ignore_prefixes\n\u001b[32m    791\u001b[39m )\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m    796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/dataset.py:476\u001b[39m, in \u001b[36m_filesystem_dataset\u001b[39m\u001b[34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[39m\n\u001b[32m    474\u001b[39m         fs, paths_or_selector = _ensure_multiple_sources(source, filesystem)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     fs, paths_or_selector = \u001b[43m_ensure_single_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m options = FileSystemFactoryOptions(\n\u001b[32m    479\u001b[39m     partitioning=partitioning,\n\u001b[32m    480\u001b[39m     partition_base_dir=partition_base_dir,\n\u001b[32m    481\u001b[39m     exclude_invalid_files=exclude_invalid_files,\n\u001b[32m    482\u001b[39m     selector_ignore_prefixes=selector_ignore_prefixes\n\u001b[32m    483\u001b[39m )\n\u001b[32m    484\u001b[39m factory = FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyarrow/dataset.py:441\u001b[39m, in \u001b[36m_ensure_single_source\u001b[39m\u001b[34m(path, filesystem)\u001b[39m\n\u001b[32m    439\u001b[39m     paths_or_selector = [path]\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filesystem, paths_or_selector\n",
      "\u001b[31mFileNotFoundError\u001b[39m: weather3/main/weather.parquet"
     ]
    }
   ],
   "source": [
    "path_all_partition = 's3a://weather3/main/weather.parquet'\n",
    "\n",
    "df2=pd.read_parquet(    \n",
    "    path=path_all_partition,\n",
    "    storage_options=storage_options\n",
    ")\n",
    "df2.info()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483f8da-bc2a-4147-8684-4c5310a0472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_single_partition = 's3a://weather3/main/weather.parquet/year=2025/month=4/day=10/hour=7/70cf855c5c5e4659ae01aba885c731c3-0.parquet'\n",
    "\n",
    "df2=pd.read_parquet(    \n",
    "    path=path_single_partition,\n",
    "    storage_options=storage_options,\n",
    ")\n",
    "df2.info()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6909c16e-e300-40b2-b9b0-2c9ecad69c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 07:31:35.485335+06:42\n"
     ]
    }
   ],
   "source": [
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d82d9f-46e6-4148-aa59-c402867f7529",
   "metadata": {},
   "source": [
    "# Test Duck and Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0392960c-a68b-4b92-8981-0379fd93b7b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'duckdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# pip install duckdb\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mduckdb\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Connect to an in-memory DuckDB instance.\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'duckdb'"
     ]
    }
   ],
   "source": [
    "# pip install duckdb\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to an in-memory DuckDB instance.\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "storage_options = {\n",
    "    \"key\": ACCESS_KEY,\n",
    "    \"secret\": SECRET_KEY,\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": lakefs_endpoint\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use DuckDB's read_parquet() function to read the dataset.\n",
    "# Assume the dataset is stored in the directory \"output_parquet_dataset\" with hive partitions:\n",
    "# output_parquet_dataset/year=2025/month=02/day=17/...\n",
    "query = \"\"\"\n",
    "INSTALL httpfs;\n",
    "LOAD httpfs;\n",
    "\n",
    "SET s3_endpoint='lakefs-dev:8000';\n",
    "SET s3_access_key_id='access_key'; \n",
    "SET s3_secret_access_key='secret_key'; \n",
    "SET s3_url_style='path';\n",
    "SET s3_use_ssl=false;\n",
    "\n",
    "SELECT *\n",
    "FROM read_parquet('s3a://weather3/main/weather.parquet')\n",
    "\"\"\"\n",
    "\n",
    "df_duck = con.execute(query).df()\n",
    "\n",
    "print(\"DuckDB Parquet Query Result:\")\n",
    "df_duck.info()\n",
    "df_duck.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c6a0fe-a4e2-40bc-96bc-e72445f8a352",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# pip install dask\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mdask\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mdd\u001b[39;00m\n\u001b[32m      3\u001b[39m df2 = dd.read_parquet(\n\u001b[32m      4\u001b[39m     path=path_all_partition,\n\u001b[32m      5\u001b[39m     storage_options=storage_options,\n\u001b[32m      6\u001b[39m     dtype_backend=\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m )  \n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dask'"
     ]
    }
   ],
   "source": [
    "# pip install dask\n",
    "import dask.dataframe as dd\n",
    "df2 = dd.read_parquet(\n",
    "    path=path_all_partition,\n",
    "    storage_options=storage_options,\n",
    "    dtype_backend='pyarrow'\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b1845-b226-47bb-b9ff-cd542c8badcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa752b31-2de0-49c5-90eb-b9fd5256fce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264ce74-dfa3-44ed-86b5-dd0059e785ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1391f57-a4b3-4d7c-96c4-f1b22b138579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7ee9d-8af8-45f9-ac46-b90a4e89cd12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
